#!/bin/bash
# Rudimentary link checker.
# This makes a lot of assumptions, and doesn't do any real parsing

if [[ $1 == "" ]]; then
    echo "Usage: check_links FILE"
    exit 1
fi

if command -v mdf &> /dev/null; then
    PRINT_CMD="mdf"
else
    PRINT_CMD="echo"
fi
 
html_file=$(realpath "$1")
root_dir=$(dirname "$(realpath "$0")")/..
outputs_dir=$root_dir/build/output
html_dir=$(dirname "$html_file")
domain=reneevandervelde.com

file_exists_locally() {
    local file="$1"

    if [ -f "$file" ] || [ -d "$file" ]; then
        $PRINT_CMD "+ Valid: $file"
    else
        $PRINT_CMD ">> Not Found: $file"
        exit 1;
    fi
}

check_link() {
    local link="$1"

    if [[ $link == mailto:* ]]; then
        $PRINT_CMD "> Skipping mailto link: $link"
    elif [[ $link == http* ]]; then
        if [[ $link = *$domain* ]]; then
            local file_path="$outputs_dir/${link#*$domain/}"
            file_exists_locally "$file_path" || exit 1
        else
            if [[ $link == *linkedin.com* ]]; then
                # linkedin links return a 999 and I don't want to fucking deal with it.
                $PRINT_CMD "> skipping link: $link"
            elif curl --output /dev/null --silent --head --fail "$link"; then
                $PRINT_CMD "+ Valid: $link"
            else
                $PRINT_CMD ">> Invalid: $link"
                exit 1;
            fi
        fi
    else
        local file_path="$html_dir/$link"
        file_exists_locally "$file_path" || exit 1
    fi
}

while IFS= read -r line; do
    links=$(echo "$line" | grep -oE 'href="([^"#]+)"' | cut -d'"' -f2)

    for link in $links; do
        check_link "$link"
    done

    links=$(echo "$line" | grep -oE '<link>[^<]+</link>' | sed -E 's/<\/?link>//g' | sed -E 's/#.*$//')
    for link in $links; do
        check_link "$link"
    done

    links=$(echo "$line" | grep -oE '<loc>[^<]+</loc>' | sed -E 's/<\/?loc>//g' | sed -E 's/#.*$//')
    for link in $links; do
        check_link "$link"
    done
done < "$html_file"
