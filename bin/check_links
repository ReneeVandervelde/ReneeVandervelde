#!/bin/bash
# Rudimentary link checker.
# This makes a lot of assumptions, and doesn't do any real parsing

if [[ $1 == "" ]]; then
    echo "Usage: check_links FILE"
    exit 1
fi
 
html_file=$(realpath "$1")
root_dir=$(dirname "$(realpath "$0")")/..
html_dir=$(dirname "$html_file")
domain=reneevandervelde.com

file_exists_locally() {
    local file="$1"

    if [ -f "$file" ] || [ -d "$file" ]; then
        echo "+ Valid: $file"
    else
        echo ">> Not Found: $file"
        exit 1;
    fi
}

check_link() {
    local link="$1"

    if [[ $link == mailto:* ]]; then
        echo "> Skipping mailto link: $link"
    elif [[ $link == http* ]]; then
        if [[ $link = *$domain* ]]; then
            local file_path="$root_dir/${link#*$domain/}"
            file_exists_locally "$file_path"
        else
            if [[ $link == *linkedin.com* ]]; then
                # linkedin links return a 999 and I don't want to fucking deal with it.
                echo "> skipping link: $link"
            elif curl --output /dev/null --silent --head --fail "$link"; then
                echo "+ Valid $link"
            else
                echo ">> Invalid: $link"
                exit 1;
            fi
        fi
    else
        local file_path="$html_dir/$link"
        file_exists_locally "$file_path"
    fi
}

while IFS= read -r line; do
    links=$(echo "$line" | grep -oE 'href="([^"#]+)"' | cut -d'"' -f2)

    for link in $links; do
        check_link "$link"
    done

    links=$(echo "$line" | grep -oE '<link>[^<]+</link>' | sed -E 's/<\/?link>//g' | sed -E 's/#.*$//')
    for link in $links; do
        check_link "$link"
    done
done < "$html_file"
